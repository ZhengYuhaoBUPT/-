# 知网爬虫遇到验证码 通过关键词爬虫
键入关键字进行知网爬虫

主要通过python实现代码，主要的依赖库是selenium，pytesseract。

# 为什么有两个函数？
其中爬虫.py是所谓的main函数，实现爬虫的主要功能。

myverify.py是实现验证码识别使用的函数。

因为在我第一次尝试用爬虫.py爬虫的时候发现会出现验证码，也就是所谓的安全检测，于是乎搞了一个验证码检测消除影响。

# 关于验证码安全检测后续
在后面跑程序的时候发现似乎myverify.py程序不要也可以，因为似乎出现了验证码也能爬得下来。。。虽然第一次尝试的时候是爬不下来的。。。相当于白搞（或者说被知网摆了一道）。

不过myverify.py在测试的时候表现还是不错的。


# 如何使用？
1.首先运行爬虫.py程序，浏览器driver就跳出来了，这时候不要将其关闭。

2.然后在运行结果处会出现输入，键入你想要查询的关键词

![image](https://user-images.githubusercontent.com/56500982/218065177-33e62834-6f94-495b-8ab4-7b047c2e91a9.png)

3.回车！这样就可以查询啦。

4.需要注意的是我在这里设置的是只查询6页并爬虫结果，若想修改查询数量，只需要在代码中找到page变量修改一下啦。

5.最终的爬虫结果保存为xls形式，如图所示。在这里我只收集了标题、作者、网址、来源等一类信息，需要修改的话请自行增添代码啦！
![image](https://user-images.githubusercontent.com/56500982/218066189-f53d277a-bee1-4384-be8c-066ac3bf88ab.png)

# 验证码
在这里上传个图片吧，展示一下安全检测的漏洞，并在没有输入验证码就爬下来数据了，然而昨天的时候还不行。。。所以才创造的myverify.py。。。不过没有大碍啦！

![Uploading image.png…]()
